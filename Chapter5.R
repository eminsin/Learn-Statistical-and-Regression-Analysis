# This document belongs to the book "Using R for Introductory Statistics" by John Verzani.
# copyright (c) 2004 - Taylor and Francis
#
# In the document, foundations of statistical knowledge is practiced on R.
#
# written by Erkam Minsin
#
# last modified: Dec 2022
# first written: Dec 2022

setwd("C:/Users/erkam/R Learning/Using_R_for_Introductory_Statistics_John_Verzani")

## install.packages("UsingR")
library(UsingR)

## update.packages()


# Chapter 5 Describing Populations ---------------------------------------------


# statistical inference is the process of forming judgments about a population based on a sample from the population

# 5.1 Populations

# 5.1.1 Discrete random variables

k=0:4
p=c(1,2,3,2,1)/9
plot(k,p,type="h",xlab="k",
     ylab="probability",ylim=c(0,max(p)))
points(k,p,pch=16,cex=2)                         # add the balls to top of spike

# Using sample() to generate random values
k=0:2                                            # data vector that the values we are sampling from
p=c(1,2,1)/4                                     # probabilities of each value being selected
sample(k,size=1,prob = p)
sample(k,size=2,prob = p)

# default value prob= make each value of k equally likely.

sample(1:6,size=1)+sample(1:6,size=1)

# The mean and standard deviation of a discrete random variable

# the population mean (expected value) of X is a weighted average of the values in the range of X
# the population standard deviation is the population variance measures spread in terms of the expected squared distance from the mean

# 5.1.2 Continuous random variables

# The p.d.f. and c.d.f.  

# The mean and standard deviation of a continuous random variable

# Quantiles of a continuous random variable

# 5.1.3 Sampling from a population

# Random samples generated by sample()

# replace=TRUE produces i.i.d sample. Default is replace=FALSE

# toss a coin 10 times. Heads=1, tails=0
sample(0:1,size=10,replace=TRUE) 

# roll a die 10 times
sample(1:6,size=10,replace=TRUE)

# sum of dice roll 10 times
sample(1:6,size=10,replace = TRUE)+sample(1:6,size = 10,replace = TRUE)

# example : public-opinion polls as random samples
sample(rep(0:1,c(3200,6800)),
       size=10,replace = TRUE)                   # rep() function produces 10000 values: 3200:0 and 6800:1.

sample(0:1,size=10,
       replace = T,prob=c(1-.62,.62))            # target population: with defined (known)proportions or probabilities

# 5.1.4 Sampling distributions

# Problems 5.1.5 

# Question 5.1
sample(0:1,size=2,replace = T)

# Question 5.2
x=max(sample(1:6,size=2,replace = T))

# Question 5.3
with(nba.draft,sample(Team, size=1,prob=Balls,replace=TRUE))

# Question 5.4

# Question 5.5

# Question 5.6

# Question 5.7
sample(0:1,size=2,replace=T)

# 5.2 Families of distributions

# d:p.d.f.
# p:c.d.f.
# q:quantiles
# r:random samples from a distribution

dunif(x=1,min=0,max=3)
punif(q=2,min=0,max=3)
qunif(p=1/2,min=0,max=3)
runif(n=1,min=0,max=3)

# vectors
ps=seq(0,1,by=.2)
names(ps)=as.character(seq(0,100,by=20))
qunif(ps,min=0,max=1)

# five different distributions
runif(5,min=0,max=1:5)                           # recycle min

# 5.2.2 Binomial, normal, and some other named distributions

# Bernoulli random variables
n=10
p=1/4
sample(0:1, size=10, replace = TRUE, prob = c(1-p,p))

# Binomial random variables
choose(10,5)*(0.5)^5*(0.5)^(10-5)                # to find Bin(n=10,p=0.5) manually

dbinom(5,size=10,prob=0.5) 

# P(X<=6)
sum(dbinom(0:6,size=10,prob=0.5))                # or
pbinom(6,size=10,prob=0.5)

# P(X>=7)
sum(dbinom(7:10,size=10,prob=.5))                # or
1-pbinom(6,size=10,prob = .5)                    # or
pbinom(6,size = 10,prob = .5,
       lower.tail = FALSE)                       # k=6 not 7!

# spike plot of X
heights <- dbinom(0:10,size=10,prob=.5)
plot(0:10, heights, type = "h",
     main = "Spike plot of X",
	 xlab = "k", ylab = "p.d.f.")
points(0:10, heights, pch = 16, cex = 2)

# example : binomial model for a public-opinion poll

# 62% of 100 people said "Yes". 
# What is the probability that 60% or less of the sample (100 people) responded "Yes"?
pbinom(60,size=100,prob=0.62) 

# Normal random variables
pnorm(1.5,mean=0,sd=1)
pnorm(4.75,mean=4,sd=0.5)                        # same z-score as above

qnorm(c(.25,.5,.75))                             # default mean=0, sd=1 

pnorm(1)-pnorm(-1)                               # returns the area of no more than one sd from the mean (~68%)                   
                                                 
# for 2 sd distance from the mean
1-2*pnorm(-2)                                    # subtract area of two tails (~95%)

# for 3 sd distance from the mean
diff(pnorm(c(-3,3)))                             # use diff to subtract (~99.7%)

# Example
mu=70.2;sigma=2.89
1-pnorm(72,mean=mu,sd=sigma)                     # 26.67%, 6 feet (72 inches) or shorter

# 1 inch=2.54cm=0.0254 m
conv=0.0254
1-pnorm(2/conv,mean=mu,sd=sigma)                 # 0.15%, 2 meters or taller

# Assuming the male population in the world is 2.5 billion. Tallest man would be in the top 1/2500000000 quantile.
p=1-1/2500000000
qnorm(p,mean=mu,sd=sigma)/12                     # poor prediction

# Example
mu=100; sigma=10
res=rnorm(1000,mean=mu,sd=sigma)
k=1;sum(res>mu-k*sigma&res<mu+k*sigma)           # 651 points of 1000, 65.1%
k=2;sum(res>mu-k*sigma&res<mu+k*sigma)           # 952 points of 1000, 95.2%
k=3;sum(res>mu-k*sigma&res<mu+k*sigma)           # 994 points of 1000, 99.4%

# 5.2.3 Popular distributions to describe populations

# many populations are well described by the normal distribution; some are not

# uniform distribution

# the unifrom distribution on [a,b] is useful to describe populations that have no preferred values over their range
# for a finite range of values, the sample() function can choose one with equal probabilities
# it is used when there is a range of values that is continuous
# the density is a constant on [a,b]
# the total area is 1, the height is 1 / (b-a)
# the mean is in the middle of the interval, mu = (a+b) / 2
# the variance is (b-a)^2 / 12
# the family name in R is unif
# parameters are min= and max= with defaults 0 and 1
# we use Uniform(a,b) to denote this distribution

res <- runif(50, min = 0, max = 10)
par(fig = c(0,1,0,0.35))                         # fig=setting uses bottom 35% of diagram
boxplot(res, horizontal = TRUE,
        bty = "n", xlab = "uniform sample")
par(fig = c(0,1,0.25,1), new = TRUE)             # fig=setting uses top 75% of figure
hist(res, prob = TRUE, main = "", 
     col = gray(0.9))
lines(density(res), lty = 2)
curve(dunif(x, min = 0, max = 10),
       lwd = 2, add = TRUE)
rug(res)

# exponential distribution

# the exponential distribution is an example of a skewed distribution
# it is a popular model for populations such as the length of time a light bulb lasts
# the parameter lambda is related to the mean by mu = 1 / lambda
# and to the standard deviation by sigma = 1 / lambda
# In R, the family name is exp
# the parameter is labeled rate=
# we refer to this distribution as Exponential(lambda)

res <- rexp(50, rate = 1/5)
## boxplot
par(fig = c(0,1,0,.35))
boxplot(res, horizontal = TRUE, bty = "n",
        xlab = "exponential sample")
## histogram
par(fig = c(0,1,.25,1), new = TRUE)
## store values, then find largest y one to set ylim=
tmp.hist <- hist(res, plot = FALSE)
tmp.edens <- density(res)
tmp.dens <- dexp(0, rate = 1/5)
y.max <- max(tmp.hist$density, tmp.edens$y, tmp.dens)
## make plots
hist(res, ylim = c(0,y.max), prob = TRUE, main = "", col = gray(0.9))
lines(density(res), lty = 2)
curve(dexp(x, rate = 1/5), lwd = 2, add = TRUE)
rug(res)

# lognormal distribution

# the lognormal distribution is a heavily skewed continuous distribution on the positive numbers
# a lognormal random variable, X, has its name as log(X) is normally distributed
# lognormal distributions describe populations such as income distribution
# In R, the family name lnorm
# the two parameters are labeled meanlog= and sdlog=
# these are the mean and sd of log(X), not of X

# 5.2.4 Sampling distributions

# three distributions to use to describe sampling distributions
# t-distribution, F-distribution, and chi-squared distribution
# the family names in R are t,f,and chisq
# their parameters are termed "degrees of freedom" and related to the sample size
# for the t- and chi-squared distributions, the degrees-of-freedom argument is df=
# for the F-distribution, as two degrees of freedom are specified, the arguments are df1= and df2=

# for example, values 1 and r for each distribution containing 95% of the area can be found as follows:

qt(c(.025,.975), df = 10)                        # t-dist, 10 degrees of freedom
qf(c(.025,.975), df1 = 10, df2 = 5)              # F-dist, 10 and 5 degrees of freedom
qchisq(c(.025,.975), df = 10)                    # chi-squared dist, 10 degrees of freedom

# Problems 5.2.5

# Question 5.8
choose(5,3)*(1/6)^3*(5/6)^2 + choose(5,4)*(1/6)^4*(5/6)^1 + choose(5,5)*(1/6)^5*(5/6)^0
sum(dbinom(3:5, size=5, prob = 1/6))
1 - pbinom(2, size = 5, prob = 1/6)
pbinom(2, size = 5, prob = 1/6, lower.tail = FALSE)

# Question 5.9
dbinom(12, size =12, prob = 0.3)

# Question 5.10
pbinom(50200, size = 100000, prob = 0.5) - pbinom(49800, size = 100000, prob = 0.5) + dbinom(49800, 100000, 0.5)
sum(dbinom(49800:50200, size = 100000, prob = 0.5))

# Question 5.11
dbinom(4,size = 4, prob = 1/3)

# Question 5.12
1 - pbinom(0, size = 24, prob = 1/36)
1 - pbinom(0, size = 4, prob = 1/6)

# Question 5.13
pbinom(35, size = 100, prob = 0.4)

# Question 5.14
pnorm(2.2, mean = 0, sd = 1)                     # 1
1 - pnorm(-2.2, mean = 0, sd = 1)                # 1
pnorm(2, 0, 1) - pnorm(-1, 0, 1)                 # 2
1 - pnorm(2.5, 0, 1)                             # 3
qnorm(0.90, 0, 1)                                # 4

# Question 5.15
1 - pnorm(450, 350, 75)

# Question 5.16
one <- pnorm(36, 20.6, 5.5) 
one - pnorm(22, 20.6, 5.5)                      

1000000 * diff(pnorm(c(22,23), mean=20.6, sd=5.5))

# Question 5.17
pnorm(26, mean=24.9, sd=1.05)
qnorm(0.95, mean=24.9, sd=1.05)

# Question 5.18
diff(pnorm(c(3.5,4), mean=3.20, sd=0.35))

# Question 5.19
1- diff(pnorm(c(-6,6), mean=0, sd=1))

# Question 5.20
pnorm(10.7, mean=12, sd=0.5)

# Question 5.21
with(father.son, diff(pnorm(c((mean(fheight)-sd(fheight)), (mean(fheight)+sd(fheight))), 
                            mean=mean(fheight), sd=sd(fheight))))

with(father.son, diff(pnorm(c((mean(fheight)-2*sd(fheight)), (mean(fheight)+2*sd(fheight))), 
                            mean=mean(fheight), sd=sd(fheight))))

with(father.son, diff(pnorm(c((mean(fheight)-3*sd(fheight)), (mean(fheight)+3*sd(fheight))), 
                            mean=mean(fheight), sd=sd(fheight))))

# Question 5.22
ps=seq(0,1,by=.2)
names(ps)=as.character(seq(0,100,by=20))
qnorm(ps,mean=0,sd=1)

# Question 5.23
diff(punif(c(1/2-sqrt(1/12), 1/2+sqrt(1/12)), min=0, max=1))
diff(punif(c(1/2-2*sqrt(1/12), 1/2+2*sqrt(1/12)), min=0, max=1))
diff(punif(c(1/2-3*sqrt(1/12), 1/2+3*sqrt(1/12)), min=0, max=1))

diff(pexp(c(0,10), rate=1/5))
diff(pexp(c(-5,15), rate=1/5))
diff(pexp(c(-10,20), rate=1/5))

# Question 5.24
qqnorm(runif(100, min=0, max=1))                 # short-tailed
qqnorm(rnorm(100, mean=0, sd=1))
qqnorm(rt(100, df=3))                            # long-tailed

# Question 5.25
curve(dnorm(x), -4, 4)
k <- 5                                           # later try with k=10,25,50,100
curve(dt(x, df=k), lty=k, add=TRUE)

# Question 5.26
curve(dchisq(x, df=2), 0, 100)
k <- 8                                           # later try with k=18,32,50,72
curve(dchisq(x, df=k), add=TRUE)

# 5.3 The central limit theorem

# 5.3.1 Normal parent population

n <- 25
curve(dnorm(x, mean=0, sd=1/sqrt(n)), -3, 3,
      xlab="x", ylab="Densities of sample mean", bty="l")
n <- 5
curve(dnorm(x, mean=0, sd=1/sqrt(n)), add=TRUE)
n <- 1
curve(dnorm(x, mean=0, sd=1/sqrt(n)), add=TRUE)
# the center stays the same, but as n gets bigger, the spread of Xbar (sampling distribution) gets smaller and smaller
# if the sample size goes up by a factor of 4, the sd goes down by 1/2, and
# the density concentrates on the mean
# that is, with greater and greater probability, the random value of Xbar is close to the mean,mu, of the parent population
# this phenomenon of the sample average concentrating on the mean is known as the law of large numbers

# example
mu <- 70.2                                       # population mean
sigma <- 2.89                                    # population sd
n <- 25
diff(pnorm(70:71, mu, sigma/sqrt(n)))            # 0.5522: the prob of a sample average is between 70 and 71 inches

# the more the sample size is, the higher the probability will be 

# let us compare this fo the prob for a single person, where n <- 1

diff(pnorm(70:71, mu, sigma))                    # 0.1366 : the prob of a single person is between 70 and 71 inches                

# 5.3.2 Nonnormal parent population

# the central limit theorem states that for any parent population with mean mu and sd sigma,
# for n big enough, the distribution of Xbar once standardized is approximately a standard normal distribution
# we also refer to this as saying Xbar is asymptotically normal

# example
pnorm(0.9, mean=1, sd=1/sqrt(20))

# Problems 5.3.3

# the central limit theorem (normal approximation) questions

# Question 5.27
n = 100; p = 1/2; b = 42
pbinom(b,n,p)                                    # binomial dist prob
pnorm(b+1/2, n*p, sqrt(n*p*(1-p)))               # binomial dist by the normal approximation 

# Question 5.28
n = 600; p = 0.300; phat = 0.350; b = n*phat
1 - pnorm(b-1/2, n*p, sqrt(n*p*(1-p)))

# Question 5.29
n = 1000; p = 0.5; b = 550
1 - pnorm(b-1/2, n*p, sqrt(n*p*(1-p)))

# Question 5.30
1 - pnorm(3500/15, mean=180, sd=25/sqrt(15))     # noname dist solved by normal approximation (assuming n=15 is large enough)

# Question 5.31
1 - pnorm(775/30, mean=25, sd=sqrt(4)/sqrt(30))  # noname dist solved by normal approximation (assuming n=30 is large enough)

# Question 5.32
pnorm(75/21, mean=4, sd=sqrt(1)/sqrt(21))        # noname dist solved by normal approximation (assuming n=21 is large enough)
